{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHisiCDtkoR",
        "outputId": "ab3422ff-0c73-48a4-ee81-a2cd7b07e472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 15s 0us/step\n",
            "170508288/170498071 [==============================] - 15s 0us/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                262176    \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 393,962\n",
            "Trainable params: 393,322\n",
            "Non-trainable params: 640\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 298s 379ms/step - loss: 1.5754 - accuracy: 0.4404 - val_loss: 1.6033 - val_accuracy: 0.4523\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 275s 352ms/step - loss: 1.1366 - accuracy: 0.5995 - val_loss: 0.9580 - val_accuracy: 0.6644\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 269s 344ms/step - loss: 0.9789 - accuracy: 0.6596 - val_loss: 0.7946 - val_accuracy: 0.7136\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 271s 346ms/step - loss: 0.8894 - accuracy: 0.6926 - val_loss: 0.7803 - val_accuracy: 0.7256\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 273s 349ms/step - loss: 0.8177 - accuracy: 0.7167 - val_loss: 0.6912 - val_accuracy: 0.7555\n",
            "Accuracy: 75.55%\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "from tensorflow import keras\n",
        "from keras.constraints import maxnorm\n",
        "from keras.utils import np_utils\n",
        "seed = 21\n",
        "from keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "class_num = y_test.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model.add(keras.layers.MaxPooling2D(2))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "model.add(keras.layers.Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Dense(class_num, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    }
  ]
}